{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, pipeline, EvalPrediction\nfrom sklearn.metrics import f1_score, accuracy_score, roc_auc_score\nfrom transformers import EvalPrediction\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:14:55.574489Z","iopub.execute_input":"2024-06-18T19:14:55.575474Z","iopub.status.idle":"2024-06-18T19:15:13.305057Z","shell.execute_reply.started":"2024-06-18T19:14:55.575425Z","shell.execute_reply":"2024-06-18T19:15:13.304228Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-06-18 19:15:04.273036: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-18 19:15:04.273132: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-18 19:15:04.409019: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# HateXplain Dataset\n\n### Content\n- **Textual Data**: The dataset contains social media posts from Twitter and Gab.\n- **Labels**: Each post is labeled as \"normal,\" \"offensive,\" or \"hate,\" indicating the severity of the language.\n\n### Annotations\n- **Label Annotations**: Posts are annotated by multiple human annotators to ensure consistent labeling.\n- **Rationales**: Annotators provide explanations highlighting specific parts of the text that influenced their labeling decision.\n- **Target Communities**: Annotations include information on which communities or groups are targeted by the hate speech.","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"hatexplain\", trust_remote_code=True)\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:13.307131Z","iopub.execute_input":"2024-06-18T19:15:13.308169Z","iopub.status.idle":"2024-06-18T19:15:25.342403Z","shell.execute_reply.started":"2024-06-18T19:15:13.308130Z","shell.execute_reply":"2024-06-18T19:15:25.341441Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.78k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fe35196380e4de49d58d351fc85ba97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/10.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"108be5688c81419d851066ce35f5ea89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c02282a195344de18b8087ff498efc17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/145k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce39693ea00d4de48057cbdb9ae9e8f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/15383 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa01dd872a7547feb5f417f20fe6c767"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1922 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efbd9ef2f02e4522a285911b299e8be4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1924 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83f583252a8b498585d23f8a7c251c9a"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'annotators', 'rationales', 'post_tokens'],\n        num_rows: 15383\n    })\n    validation: Dataset({\n        features: ['id', 'annotators', 'rationales', 'post_tokens'],\n        num_rows: 1922\n    })\n    test: Dataset({\n        features: ['id', 'annotators', 'rationales', 'post_tokens'],\n        num_rows: 1924\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing\n- I'll classify both the offensiveness in a ordinal fashion\n- and the targets of the sentence","metadata":{}},{"cell_type":"code","source":"X_train = dataset[\"train\"][\"post_tokens\"]\nX_val = dataset[\"validation\"][\"post_tokens\"]\nX_test = dataset[\"test\"][\"post_tokens\"]\n\nX_train = [\" \".join(sublist) for sublist in X_train]\nX_val = [\" \".join(sublist) for sublist in X_val]\nX_test = [\" \".join(sublist) for sublist in X_test]\n\ny_train_lbl = dataset[\"train\"][\"annotators\"]\ny_val_lbl = dataset[\"validation\"][\"annotators\"]\ny_test_lbl = dataset[\"test\"][\"annotators\"]\n\ny_train_lbl = [el[\"label\"] for el in y_train_lbl]\ny_val_lbl = [el[\"label\"] for el in y_val_lbl]\ny_test_lbl = [el[\"label\"] for el in y_test_lbl]\n\ny_train_targets = dataset[\"train\"][\"annotators\"]\ny_val_targets = dataset[\"validation\"][\"annotators\"]\ny_test_targets = dataset[\"test\"][\"annotators\"]\n\ny_train_targets = [el[\"target\"] for el in y_train_targets]\ny_val_targets = [el[\"target\"] for el in y_val_targets]\ny_test_targets = [el[\"target\"] for el in y_test_targets]\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:25.344131Z","iopub.execute_input":"2024-06-18T19:15:25.344394Z","iopub.status.idle":"2024-06-18T19:15:27.656253Z","shell.execute_reply.started":"2024-06-18T19:15:25.344370Z","shell.execute_reply":"2024-06-18T19:15:27.655416Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"id1 = 140\nid2 = 145\n\nfor el1, el2, el3 in zip(X_train[id1:id2],y_train_lbl[id1:id2],y_train_targets[id1:id2]):\n    print(el1,el2,el3,sep=\"\\n\",end=\"\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:27.658196Z","iopub.execute_input":"2024-06-18T19:15:27.658492Z","iopub.status.idle":"2024-06-18T19:15:27.664360Z","shell.execute_reply.started":"2024-06-18T19:15:27.658467Z","shell.execute_reply":"2024-06-18T19:15:27.663379Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"lesson of the week from the holy book the sovereign individual once commerce flows over the internet suppression of speech becomes unstoppable devolution inevitable and the monopoly of violence by governments will end paraphrased from j d davidson rhys mogg\n[1, 1, 1]\n[['None'], ['None'], ['None']]\n\nwatch bbc on muslims abandoning eu <number> syria the father honestly says it bcs they do not like girls being told they have freewill by supposedly educated pple bcs women don t in islam sharia sharialaw realitycheck fgm misogyny hijab rapeculture abuse violence woman women girl girls womansrights womensrights brexit\n[1, 1, 1]\n[['Islam', 'Women'], ['Arab', 'Islam', 'Women'], ['Arab', 'Islam']]\n\n<user> whatchu are <user> is a self hating homosexual who has to pay for your homosexual desires\n[2, 2, 2]\n[['Homosexual'], ['Homosexual'], ['Homosexual']]\n\nthe parade needed at least one severed head in honor of muslim culture\n[0, 2, 0]\n[['Islam'], ['Islam'], ['Islam']]\n\ni look at the mudslime news from europe and think i wish some goat fucker would try that shit down here in louisiana just get within <number> feet of my daughters and thats your life over checkout time mohammed\n[0, 0, 0]\n[['Islam'], ['Men', 'Minority', 'Refugee', 'Arab', 'Islam', 'Heterosexual'], ['Refugee', 'Islam']]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Preparing Labels\n\nI will average and normalize the label values. The actual situation is that for every sentence we have three different annotation which can take the 3 values:\n- 0 - hatespeech\n- 1 - normal\n- 2 - offensive\n\nI'll first reorder them, so that\n\n- 2 = hate\n- 1 = offensive\n- 0 = normal\n\nthan, since for each sentence there are three different annotation, I'll average them and normalize in the range [0, 1]\n\n(e.g., \"they playing a lot of ethnic music at this white ass wedding\" has labels [2, 1, 1] -> [1, 0, 0] -> 0.333 -> 0.165)","metadata":{}},{"cell_type":"code","source":"lbl_map = {\n    0:2,\n    1:0,\n    2:1\n}\n\ndef avg3(ls):\n    return (lbl_map[ls[0]]+lbl_map[ls[1]]+lbl_map[ls[2]])/6\n\ny_train_lbl = [avg3(x) for x in y_train_lbl]\ny_val_lbl = [avg3(x) for x in y_val_lbl]\ny_test_lbl = [avg3(x) for x in y_test_lbl]","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:27.665557Z","iopub.execute_input":"2024-06-18T19:15:27.665821Z","iopub.status.idle":"2024-06-18T19:15:27.688702Z","shell.execute_reply.started":"2024-06-18T19:15:27.665798Z","shell.execute_reply":"2024-06-18T19:15:27.687722Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"I'll also hold a categorical equivalent:\n- normal  (0 -> 0.33)\n- offensive (0.33 -> 0.66)\n- hatespeech  (0.66 -> 1)","metadata":{}},{"cell_type":"code","source":"def ordinalToCategorical (hateScore):\n    if hateScore < 0.33:\n        return 0\n    elif hateScore < 0.66:\n        return 1\n    else:\n        return 2\n    \ny_train_lbl_cat = [ordinalToCategorical(i) for i in y_train_lbl]\ny_val_lbl_cat = [ordinalToCategorical(i) for i in y_val_lbl]\ny_test_lbl_cat = [ordinalToCategorical(i) for i in y_test_lbl]\ny_train_lbl_cat[:20]","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:27.689876Z","iopub.execute_input":"2024-06-18T19:15:27.690185Z","iopub.status.idle":"2024-06-18T19:15:27.704599Z","shell.execute_reply.started":"2024-06-18T19:15:27.690162Z","shell.execute_reply":"2024-06-18T19:15:27.703781Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[2, 2, 1, 1, 1, 0, 2, 0, 0, 2, 1, 0, 0, 0, 2, 1, 2, 2, 1, 0]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Preparing Targets\n\nA similar procedure should be done also for the targets, If two of the three annotators mentioned the same target I'll maintain it","metadata":{}},{"cell_type":"code","source":"# Done by ChatGPT 4o\n\n# Prompt:\n# Suppose you have three lists of classes,\n# if the same class is in at least 2 classes\n# you add it to a new list to return. give me the code\n\nfrom collections import Counter\n\ndef find_common_classes(list1, list2, list3):\n    # Combine all lists into one\n    combined_list = list1 + list2 + list3\n    \n    # Create a counter to count occurrences of each element\n    counter = Counter(combined_list)\n    \n    # Create a list to store elements that appear in at least two of the lists\n    result = [item for item, count in counter.items() if count >= 2]\n    \n    return result","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:27.705635Z","iopub.execute_input":"2024-06-18T19:15:27.705896Z","iopub.status.idle":"2024-06-18T19:15:27.715959Z","shell.execute_reply.started":"2024-06-18T19:15:27.705873Z","shell.execute_reply":"2024-06-18T19:15:27.714954Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"y_train_targets = [find_common_classes(trgts[0],trgts[1],trgts[2]) for trgts in y_train_targets]\ny_val_targets = [find_common_classes(trgts[0],trgts[1],trgts[2]) for trgts in y_val_targets]\ny_test_targets = [find_common_classes(trgts[0],trgts[1],trgts[2]) for trgts in y_test_targets]\n\nall_targets = y_train_targets + y_val_targets + y_test_targets","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:27.717129Z","iopub.execute_input":"2024-06-18T19:15:27.717528Z","iopub.status.idle":"2024-06-18T19:15:27.809735Z","shell.execute_reply.started":"2024-06-18T19:15:27.717491Z","shell.execute_reply":"2024-06-18T19:15:27.808847Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"classes = set()\nfor ls in all_targets:\n    for el in ls:\n        classes.add(el)\n\nprint(classes)\nprint(len(classes))","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:27.810876Z","iopub.execute_input":"2024-06-18T19:15:27.811489Z","iopub.status.idle":"2024-06-18T19:15:27.822501Z","shell.execute_reply.started":"2024-06-18T19:15:27.811457Z","shell.execute_reply":"2024-06-18T19:15:27.821605Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"{'Indigenous', 'Jewish', 'Hindu', 'Indian', 'Men', 'Homosexual', 'Other', 'Hispanic', 'Disability', 'Buddhism', 'Asian', 'African', 'Christian', 'Caucasian', 'Arab', 'Women', 'Islam', 'None', 'Refugee', 'Economic'}\n20\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Removing low incidence groups for tagging","metadata":{}},{"cell_type":"code","source":"classCounter = dict()\n\nfor el in classes:\n    classCounter[el] = 0\n\nfor ls in all_targets:\n    for el in ls:\n        classCounter[el] += 1\n\nsorted_classCounter = dict(sorted(classCounter.items(), key=lambda item: item[1], reverse=True))\nprint(\"number of posts where class is mentioned\",sorted_classCounter,sep=\"\\n\",end=\"\\n\\n\")\n\nconsideredClasses = set()\n\nfor el in classCounter.items():\n    if el[1] > 100:\n        consideredClasses.add(el[0])\n\nprint(\"target classes with more than 100 posts\",consideredClasses,sep=\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:27.826112Z","iopub.execute_input":"2024-06-18T19:15:27.826443Z","iopub.status.idle":"2024-06-18T19:15:27.841127Z","shell.execute_reply.started":"2024-06-18T19:15:27.826413Z","shell.execute_reply":"2024-06-18T19:15:27.840280Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"number of posts where class is mentioned\n{'None': 6514, 'African': 3166, 'Islam': 2111, 'Jewish': 1925, 'Homosexual': 1837, 'Women': 1534, 'Refugee': 848, 'Other': 755, 'Arab': 753, 'Caucasian': 497, 'Asian': 383, 'Hispanic': 357, 'Men': 84, 'Disability': 54, 'Christian': 45, 'Hindu': 17, 'Indian': 10, 'Economic': 9, 'Buddhism': 2, 'Indigenous': 1}\n\ntarget classes with more than 100 posts\n{'Arab', 'Hispanic', 'Women', 'Asian', 'Caucasian', 'African', 'Jewish', 'Islam', 'Homosexual', 'None', 'Refugee', 'Other'}\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\nfor i,ls in enumerate(y_train_targets):\n    y_train_targets[i] = [consClass for consClass in ls if consClass in consideredClasses]\n\nfor i,ls in enumerate(y_val_targets):\n    y_val_targets[i] = [consClass for consClass in ls if consClass in consideredClasses]\n\nfor i,ls in enumerate(y_test_targets):\n    y_test_targets[i] = [consClass for consClass in ls if consClass in consideredClasses]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:27.842088Z","iopub.execute_input":"2024-06-18T19:15:27.842335Z","iopub.status.idle":"2024-06-18T19:15:27.865439Z","shell.execute_reply.started":"2024-06-18T19:15:27.842313Z","shell.execute_reply":"2024-06-18T19:15:27.864603Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"This code removes:\n- entries where the targets appears less than 100 times\n- entries where all the annotators disagree on the target","metadata":{}},{"cell_type":"code","source":"print(len(X_train),len(y_train_targets))\n\n# By ChatGPT 4o [modified]\n#\n# i have a list of sentences and a list of targets\n# I want to remove each entry if the target ls is empty from both lists, how do I do it?\n\ndef removeEmptyTargetsEntries(X,y):\n\n    # Filter out entries where the target is empty\n    filtered_pairs = [(s, t) for s, t in zip(X, y) if len(t)!=0]\n\n    # Unzip the filtered pairs back into two separate lists\n    filtered_sentences, filtered_targets = zip(*filtered_pairs) if filtered_pairs else ([], [])\n\n    # Convert the tuples back to lists (if needed)\n    return list(filtered_sentences),list(filtered_targets)\n\nX_train_targets,y_train_targets = removeEmptyTargetsEntries(X_train,y_train_targets)\nX_val_targets,y_val_targets = removeEmptyTargetsEntries(X_val,y_val_targets)\nX_test_targets,y_test_targets = removeEmptyTargetsEntries(X_test,y_test_targets)\n\n\nprint(len(X_train_targets),len(y_train_targets))","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:27.866655Z","iopub.execute_input":"2024-06-18T19:15:27.867124Z","iopub.status.idle":"2024-06-18T19:15:27.888605Z","shell.execute_reply.started":"2024-06-18T19:15:27.867094Z","shell.execute_reply":"2024-06-18T19:15:27.887680Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"15383 15383\n14538 14538\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\n\nmultilabel = MultiLabelBinarizer()\n\ny_train_targets_bin = multilabel.fit_transform(y_train_targets).astype('float32')\ny_val_targets_bin = multilabel.transform(y_val_targets).astype('float32')\ny_test_targets_bin = multilabel.transform(y_test_targets).astype('float32')\n\nprint(X_train_targets[3],y_train_targets[3])\nprint(y_train_targets_bin[3])\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:27.889680Z","iopub.execute_input":"2024-06-18T19:15:27.890169Z","iopub.status.idle":"2024-06-18T19:15:27.923204Z","shell.execute_reply.started":"2024-06-18T19:15:27.890144Z","shell.execute_reply":"2024-06-18T19:15:27.922348Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"i live and work with many legal mexican immigrants who are great citizens and trump supporters they have no problem with deporting illegals maga ['Hispanic', 'Refugee']\n[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Sample example of the changed dataset","metadata":{}},{"cell_type":"code","source":"id1 = 140\nid2 = 145\n\nfor sen, lbl, catlbl, targets, targets_bin in zip(X_train[id1:id2],y_train_lbl[id1:id2],y_train_lbl_cat[id1:id2],y_train_targets[id1:id2],y_train_targets_bin[id1:id2]):\n    print(sen,lbl,f\"Category: {catlbl}\",targets,targets_bin,end=\"\\n\\n\",sep=\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:27.924385Z","iopub.execute_input":"2024-06-18T19:15:27.924706Z","iopub.status.idle":"2024-06-18T19:15:27.932294Z","shell.execute_reply.started":"2024-06-18T19:15:27.924675Z","shell.execute_reply":"2024-06-18T19:15:27.931321Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"lesson of the week from the holy book the sovereign individual once commerce flows over the internet suppression of speech becomes unstoppable devolution inevitable and the monopoly of violence by governments will end paraphrased from j d davidson rhys mogg\n0.0\nCategory: 0\n['Islam']\n[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n\nwatch bbc on muslims abandoning eu <number> syria the father honestly says it bcs they do not like girls being told they have freewill by supposedly educated pple bcs women don t in islam sharia sharialaw realitycheck fgm misogyny hijab rapeculture abuse violence woman women girl girls womansrights womensrights brexit\n0.0\nCategory: 0\n['Islam', 'Refugee']\n[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n\n<user> whatchu are <user> is a self hating homosexual who has to pay for your homosexual desires\n0.5\nCategory: 1\n['African', 'Homosexual']\n[1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n\nthe parade needed at least one severed head in honor of muslim culture\n0.8333333333333334\nCategory: 2\n['Caucasian']\n[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n\ni look at the mudslime news from europe and think i wish some goat fucker would try that shit down here in louisiana just get within <number> feet of my daughters and thats your life over checkout time mohammed\n1.0\nCategory: 2\n['Jewish']\n[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preaparing DatasetDict for Bert Models\n* the first one is for classyfing between 0,1,2 labels\n* the second one for the target groups","metadata":{}},{"cell_type":"code","source":"train_data = {'text': X_train, 'label': y_train_lbl_cat}\nval_data = {'text': X_val, 'label': y_val_lbl_cat}\ntest_data = {'text': X_test, 'label': y_test_lbl_cat}\n\ndf_train = pd.DataFrame(train_data)\ndf_val = pd.DataFrame(val_data)\ndf_test = pd.DataFrame(test_data)\n\ntrain_dataset = Dataset.from_pandas(df_train)\nval_dataset = Dataset.from_pandas(df_val)\ntest_dataset = Dataset.from_pandas(df_test)\n\nhateXplain = DatasetDict({\n    \"train\": train_dataset,\n    \"validation\": val_dataset,\n    \"test\": test_dataset\n})","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:27.933562Z","iopub.execute_input":"2024-06-18T19:15:27.933987Z","iopub.status.idle":"2024-06-18T19:15:27.992210Z","shell.execute_reply.started":"2024-06-18T19:15:27.933957Z","shell.execute_reply":"2024-06-18T19:15:27.991464Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# BERT MODELS","metadata":{}},{"cell_type":"code","source":"model_name = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef tokenize_function(batch):\n    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n\nhateXplain_encoded = hateXplain.map(tokenize_function, batched=True, batch_size=None)\n\nprint(hateXplain_encoded[\"train\"][0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_metrics(preds):\n  preds_preds = preds.predictions[0] if isinstance(preds.predictions, tuple) else preds.predictions\n  predictions = preds_preds.argmax(axis=-1)\n  labels = preds.label_ids\n\n  f1 = f1_score(labels, predictions, average='macro')\n  accuracy = accuracy_score(labels, predictions)\n  \n  return {'F1 Score': f1, 'accuracy': accuracy}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fine Tuning - {0,1,2} Labels","metadata":{}},{"cell_type":"code","source":"num_labels = 3\nid2label = {0: \"normal\", 1: \"offensive\", 2: \"hatespeech\"}\nlabel2id = {\"normal\": 0, \"offensive\": 1, \"hatespeech\": 2}\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels, id2label=id2label, label2id=label2id)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\nepochs = 2\nlogging_steps = len(hateXplain_encoded[\"train\"]) // batch_size\nmodel_name_output_dir = model_name.replace(\"/\", \"-\")+\"-finetuned-hateXplain\"\ntraining_args_ft = TrainingArguments(output_dir=model_name_output_dir,\n                                  num_train_epochs=epochs,\n                                  learning_rate=1e-4,\n                                  per_device_train_batch_size=batch_size,\n                                  per_device_eval_batch_size=batch_size,\n                                  weight_decay=0.01,\n                                  evaluation_strategy=\"epoch\",\n                                  disable_tqdm=False,\n                                  logging_steps=logging_steps,\n                                  log_level=\"error\",\n                                  optim='adamw_torch'\n                                  )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(model=model,\n                  args=training_args_ft,\n                  compute_metrics=get_metrics,\n                  train_dataset=hateXplain_encoded[\"train\"],\n                  eval_dataset=hateXplain_encoded[\"validation\"],\n                  tokenizer=tokenizer)\ntrainer.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model()\ntrainer.evaluate()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Uploading and testing","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-hateXplain')\nmodel_name = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nbatch_size = 16\nepochs = 2\n\nmodel_name_output_dir = model_name.replace(\"/\", \"-\")+\"-finetuned-hateXplain\"\ntraining_args_ft = TrainingArguments(output_dir=model_name_output_dir,\n                                  num_train_epochs=epochs,\n                                  learning_rate=1e-4,\n                                  per_device_train_batch_size=batch_size,\n                                  per_device_eval_batch_size=batch_size,\n                                  weight_decay=0.01,\n                                  evaluation_strategy=\"epoch\",\n                                  disable_tqdm=False,\n                                  log_level=\"error\",\n                                  optim='adamw_torch'\n                                  )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)\ntrainer = Trainer(model=model, args=training_args_ft, compute_metrics=get_metrics, tokenizer=tokenizer)\npreds_ft = trainer.predict(hateXplain_encoded['test'])\nprint(preds_ft.metrics)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = pipeline('text-classification', model=model, tokenizer=tokenizer)\nprint(classifier('Bruce lee worst chinese actor'))\nprint(classifier('Bruce lee chinese dog'))\nprint(classifier(\"Imagine having bruce lee in the USA government\"))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Linear Probing  - {0,1,2} Labels","metadata":{}},{"cell_type":"code","source":"print(model_name)\nnum_labels = 3\nid2label = {0: \"normal\", 1: \"offensive\", 2: \"hatespeech\"}\nlabel2id = {\"normal\": 0, \"offensive\": 1, \"hatespeech\": 2}\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels, id2label=id2label, label2id=label2id)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, param in model.named_parameters():\n    if 'classifier' not in name:\n        param.requires_grad = False\n    else:  # classifier layer\n        print(name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\nepochs = 5\nmodel_name_output_dir = model_name.replace(\"/\", \"-\")+\"-linearprob-hateXplain\"\n\ntraining_args_lp = TrainingArguments(output_dir=model_name_output_dir,\n                                  num_train_epochs=epochs,\n                                  learning_rate=1e-4,\n                                  per_device_train_batch_size=batch_size,\n                                  per_device_eval_batch_size=batch_size,\n                                  weight_decay=0.01,\n                                  evaluation_strategy=\"epoch\",\n                                  disable_tqdm=False,\n                                  log_level=\"error\",\n                                  optim='adamw_torch'\n                                  )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(model=model,\n                  args=training_args_lp,\n                  compute_metrics=get_F1,\n                  train_dataset=hateXplain_encoded[\"train\"],\n                  eval_dataset=hateXplain_encoded[\"validation\"],\n                  tokenizer=tokenizer)\ntrainer.train()\ntrainer.save_model()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Uploading and Testing - Linear Prob","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-linearprob-hateXplain')\nmodel_name = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(model=model, args=training_args_lp, compute_metrics=get_metrics, tokenizer=tokenizer, eval_dataset=hateXplain_encoded[\"validation\"])\ntrainer.evaluate()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)\npreds_probing = trainer.predict(hateXplain_encoded['test'])\nprint(preds_probing.metrics)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = pipeline('text-classification', model=model, tokenizer=tokenizer)\nprint(classifier('Bruce lee worst chinese actor'))\nprint(classifier('Bruce lee chinese dog'))\nprint(classifier(\"Imagine having bruce lee in the USA government\"))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Group Tagging with BERT - only finetuning","metadata":{}},{"cell_type":"markdown","source":"## Preprocessing Steps","metadata":{}},{"cell_type":"code","source":"# Lets build custom dataset\nclass CustomDataset(Dataset):\n  def __init__(self, texts, labels, tokenizer, max_len=128):\n    self.texts = texts\n    self.labels = labels\n    self.tokenizer = tokenizer\n    self.max_len = max_len\n\n  def __len__(self):\n    return len(self.texts)\n\n  def __getitem__(self, idx):\n    text = str(self.texts[idx])\n    label = torch.tensor(self.labels[idx])\n\n    encoding = self.tokenizer(text, truncation=True, padding=\"max_length\", max_length=self.max_len, return_tensors='pt')\n\n    return {\n        'input_ids': encoding['input_ids'].flatten(),\n        'attention_mask': encoding['attention_mask'].flatten(),\n        'labels': label\n    }\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T13:28:36.505506Z","iopub.execute_input":"2024-06-18T13:28:36.506191Z","iopub.status.idle":"2024-06-18T13:28:36.513536Z","shell.execute_reply.started":"2024-06-18T13:28:36.506160Z","shell.execute_reply":"2024-06-18T13:28:36.512515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds_trgt = CustomDataset(X_train_targets, y_train_targets_bin, tokenizer)\nval_ds_trgt = CustomDataset(X_val_targets, y_val_targets_bin, tokenizer)\ntest_ds_trgt = CustomDataset(X_test_targets, y_test_targets_bin, tokenizer)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CHAT GPT after providing codes errors\n\ndef convert_to_hf_dataset(custom_dataset):\n    data = {\n        'input_ids': [],\n        'attention_mask': [],\n        'labels': []\n    }\n    \n    for i in range(len(custom_dataset)):\n        item = custom_dataset[i]\n        data['input_ids'].append(item['input_ids'].numpy())\n        data['attention_mask'].append(item['attention_mask'].numpy())\n        data['labels'].append(item['labels'].numpy())\n        \n    hf_dataset = Dataset.from_dict(data)\n    return hf_dataset\n\n\ntrain_ds_trgt = convert_to_hf_dataset(train_ds_trgt)\nval_ds_trgt = convert_to_hf_dataset(val_ds_trgt)\ntest_ds_trgt = convert_to_hf_dataset(test_ds_trgt)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Multi-Label Classification Evaluation Metrics\ndef multi_labels_metrics(predictions, labels, threshold=0.3):\n  sigmoid = torch.nn.Sigmoid()\n  probs = sigmoid(torch.Tensor(predictions))\n\n  y_pred = np.zeros(probs.shape)\n  y_pred[np.where(probs>=threshold)] = 1\n  y_true = labels\n\n  accuracy = accuracy_score(y_true, y_pred)\n  f1 = f1_score(y_true, y_pred, average = 'macro')\n  roc_auc = roc_auc_score(y_true, y_pred, average = 'macro')\n\n  metrics = {\n      \"roc_auc\": roc_auc,\n      \"f1\": f1,\n      \"accuracy\": accuracy\n  }\n\n  return metrics\n\ndef compute_metrics(p:EvalPrediction):\n  preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n\n  result = multi_labels_metrics(predictions=preds,\n                                labels=p.label_ids)\n\n  return result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n\ncheckpoint = \"distilbert-base-uncased\"\ntokenizer = DistilBertTokenizer.from_pretrained(checkpoint)\nmodel = DistilBertForSequenceClassification.from_pretrained(checkpoint, num_labels=len(consideredClasses),\n                                                            problem_type=\"multi_label_classification\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training Arguments\nfrom transformers import TrainingArguments, Trainer\n\nmodel_name_output_dir = checkpoint.replace(\"/\", \"-\")+\"-targets-ft-hateXplain\"\n\nargs = TrainingArguments(\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    output_dir = model_name_output_dir,\n    num_train_epochs=5,\n    save_steps=1000,\n    save_total_limit=2,\n    evaluation_strategy=\"epoch\"\n)\n\ntrainer = Trainer(model=model,\n                  args=args,\n                  train_dataset = train_ds_trgt,\n                  eval_dataset = val_ds_trgt,\n                  compute_metrics=compute_metrics)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Uploading and Testing","metadata":{}},{"cell_type":"code","source":"from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n\ncheckpoint = \"distilbert-base-uncased-targets-ft-hateXplain\"\ntokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\nmodel = DistilBertForSequenceClassification.from_pretrained(checkpoint, num_labels=len(consideredClasses),\n                                                            problem_type=\"multi_label_classification\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = TrainingArguments(per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    output_dir = checkpoint,\n    num_train_epochs=5,\n    evaluation_strategy=\"epoch\"\n)\n\ntrainer = Trainer(model=model,\n                  args=args,\n                  train_dataset = train_ds_trgt,\n                  eval_dataset = val_ds_trgt,\n                  compute_metrics=compute_metrics)\n\ntrainer.evaluate()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_targets = trainer.predict(test_ds_trgt)\nprint(preds_targets.metrics)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = X_test_targets[50]\nprint(text,y_test_targets[50])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoding = tokenizer(text, return_tensors='pt')\nencoding.to(trainer.model.device)\noutputs = trainer.model(**encoding)\n\nsigmoid = torch.nn.Sigmoid()\nprobs = sigmoid(outputs.logits[0].cpu())\npreds = np.zeros(probs.shape)\npreds[np.where(probs>=0.3)] = 1\n\nmultilabel.classes_\n\nmultilabel.inverse_transform(preds.reshape(1,-1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BiRNN and simple TL-IDF linear regression","metadata":{}},{"cell_type":"markdown","source":"Use simple nltk tokenization","metadata":{}},{"cell_type":"code","source":"#let's create our tokenizer function to tokenize the sentences\nimport nltk\nnltk.download('punkt')\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nfrom nltk.tokenize import word_tokenize\nimport string\npunctuations = list(string.punctuation)\n\nstopwords_list = list(stopwords.words('english'))\n\n\ndef nltk_tokenizer(sentence):\n    #we lowercase all sentences\n    sentence = sentence.lower()\n\n    #here we tokenize it using nltk\n    my_tokenized_tokens = word_tokenize(sentence)\n\n    # Removing stop words and punctuations\n    mytokens = [word for word in my_tokenized_tokens if word not in stopwords_list and word not in punctuations]\n\n    # return preprocessed list of tokens\n    return mytokens","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:30.334724Z","iopub.execute_input":"2024-06-18T19:15:30.335303Z","iopub.status.idle":"2024-06-18T19:15:30.879369Z","shell.execute_reply.started":"2024-06-18T19:15:30.335271Z","shell.execute_reply":"2024-06-18T19:15:30.878450Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"#tokenize train/test data\nprint(\"apply tokenizer to test data\")\ndf_test['tokens'] = df_test['text'].apply(nltk_tokenizer)\ndf_test['sentence'] =  df_test.tokens.apply(lambda x: ' '.join(x))\n\n\nprint(\"apply tokenizer to train data\")\ndf_train['tokens'] = df_train['text'].apply(nltk_tokenizer)\ndf_train['sentence'] =  df_train.tokens.apply(lambda x: ' '.join(x))","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:32.191489Z","iopub.execute_input":"2024-06-18T19:15:32.192181Z","iopub.status.idle":"2024-06-18T19:15:37.754633Z","shell.execute_reply.started":"2024-06-18T19:15:32.192145Z","shell.execute_reply":"2024-06-18T19:15:37.753852Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"apply tokenizer to test data\napply tokenizer to train data\n","output_type":"stream"}]},{"cell_type":"code","source":"#first we need to define the vocabulary using the training data only!\nvocab = set()\nfor sent in df_train['sentence']:\n    for word in sent.split(\" \"):\n        vocab.add(word.strip())\n\n#print(vocab)\nprint(len(vocab))","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:37.756435Z","iopub.execute_input":"2024-06-18T19:15:37.757084Z","iopub.status.idle":"2024-06-18T19:15:37.840114Z","shell.execute_reply.started":"2024-06-18T19:15:37.757048Z","shell.execute_reply":"2024-06-18T19:15:37.839253Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"24815\n","output_type":"stream"}]},{"cell_type":"code","source":"documents_train = list(df_train.sentence)\ndocuments_test = list(df_test.sentence)\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\n\n#tfidf for the training data\nvectorizer = CountVectorizer(lowercase=True, vocabulary=vocab)\nX_count_train = vectorizer.fit_transform(documents_train)\ntransformer = TfidfTransformer()\nX_tfidf_train = transformer.fit_transform(X_count_train)\n\n#tfidf for the testing data\nvectorizer = CountVectorizer(lowercase=True, vocabulary=vocab)\nX_count_test = vectorizer.fit_transform(documents_test)\ntransformer = TfidfTransformer()\nX_tfidf_test = transformer.fit_transform(X_count_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:37.841250Z","iopub.execute_input":"2024-06-18T19:15:37.841587Z","iopub.status.idle":"2024-06-18T19:15:38.247138Z","shell.execute_reply.started":"2024-06-18T19:15:37.841555Z","shell.execute_reply":"2024-06-18T19:15:38.246319Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"Y_label_train = df_train['label'].to_list()\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\n\nclassifier = LogisticRegression(max_iter = 1000)\nclassifier.fit(X_tfidf_train, Y_label_train)\n\n\ny_test = df_test['label'].to_list()\npredicted = classifier.predict(X_tfidf_test)\npredicted_prob = classifier.predict_proba(X_tfidf_test)\nprint(\"Logistic Regression Accuracy:\", metrics.accuracy_score(y_test, predicted))\nprint(\"Logistic F1 macro:\", metrics.f1_score(y_test, predicted, average = \"macro\"))\nprint(\"Logistic ROC AUC :\", metrics.roc_auc_score(y_test, predicted_prob, multi_class='ovr'))","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:42.972977Z","iopub.execute_input":"2024-06-18T19:15:42.973845Z","iopub.status.idle":"2024-06-18T19:15:46.866607Z","shell.execute_reply.started":"2024-06-18T19:15:42.973810Z","shell.execute_reply":"2024-06-18T19:15:46.865618Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Logistic Regression Accuracy: 0.6528066528066528\nLogistic Regression Precision: 0.6022145525496255\nLogistic Regression Recall: 0.7977744029650685\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Pretrained Glove embedding and BiRNN for target and class prediction","metadata":{}},{"cell_type":"code","source":"import gensim.downloader\npretraines_glove_model = gensim.downloader.load('glove-wiki-gigaword-100')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:15:48.238693Z","iopub.execute_input":"2024-06-18T19:15:48.239088Z","iopub.status.idle":"2024-06-18T19:17:07.552726Z","shell.execute_reply.started":"2024-06-18T19:15:48.239056Z","shell.execute_reply":"2024-06-18T19:17:07.551959Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"[================================================--] 96.7% 123.9/128.1MB downloaded","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"}]},{"cell_type":"markdown","source":"Now create the embeddings","metadata":{}},{"cell_type":"code","source":"pretraines_glove_model.most_similar('terrorist')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T17:29:20.267060Z","iopub.execute_input":"2024-06-18T17:29:20.267442Z","iopub.status.idle":"2024-06-18T17:29:20.368140Z","shell.execute_reply.started":"2024-06-18T17:29:20.267412Z","shell.execute_reply":"2024-06-18T17:29:20.366795Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[('terror', 0.8976657390594482),\n ('terrorists', 0.8589985966682434),\n ('terrorism', 0.8219908475875854),\n ('attacks', 0.8140439391136169),\n ('qaida', 0.7818638682365417),\n ('qaeda', 0.7712634205818176),\n ('bombings', 0.7330332398414612),\n ('extremist', 0.7313344478607178),\n ('militant', 0.7306753396987915),\n ('suspected', 0.7263491153717041)]"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# set to collect unkown words for whic the embeddings is a null vector\nunkown_words = set()\n\n    \ndef get_word_embedding(emb_model,word, emb_dim):\n\n  if word in emb_model: #wv\n        return emb_model[word]\n  else:\n        global unkown_words\n        unkown_words.add(word)\n\n        return np.zeros(emb_dim)  # For unknown words\n\n\ndef pad_sequence(embeddings, max_length, embedding_dim):\n    if len(embeddings) < max_length:\n        padding = np.zeros((max_length - len(embeddings), embedding_dim))\n        embeddings = np.vstack((embeddings, padding))\n    else:\n        embeddings = embeddings[:max_length]\n    return embeddings\n\n\ndef create_embedding_vectors(emb_model, df_train, df_test, emb_dim):\n    \n    global unkown_words\n    \n    # decide padding dim according to longest sentence in df_train\n    max_length = max(len(sentence) for sentence in df_train['tokens'])\n    print(f\"max lenght: {max_length}\")\n    \n    \n    embedded_sentences = []\n    \n    for sentence in df_train['tokens']:\n        words = [word for word in sentence]\n\n        embeddings = [get_word_embedding(emb_model,word,emb_dim) for word in words]\n        padded_embeddings = pad_sequence(embeddings, max_length, emb_dim)\n        embedded_sentences.append(padded_embeddings)\n\n    embedded_sentences_test = []\n    for sentence in df_test['tokens']:\n      words = [word for word in sentence]\n\n      embeddings = [get_word_embedding(emb_model,word,emb_dim) for word in words]\n      padded_embeddings = pad_sequence(embeddings, max_length, emb_dim)\n      embedded_sentences_test.append(padded_embeddings)\n\n\n    print(f\" words not found: {len(unkown_words)}\")\n    \n    \n    # Organize data\n    data_test = list(zip(np.array(embedded_sentences_test), df_test[\"label\"].to_numpy()))\n    data_train = list(zip(np.array(embedded_sentences), df_train[\"label\"].to_numpy()))\n    \n    return data_train, data_test\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:18:00.774179Z","iopub.execute_input":"2024-06-18T19:18:00.774539Z","iopub.status.idle":"2024-06-18T19:18:00.793072Z","shell.execute_reply.started":"2024-06-18T19:18:00.774509Z","shell.execute_reply":"2024-06-18T19:18:00.792089Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Now we create the data tuple (X,label) for target and hate speech classification\n","metadata":{}},{"cell_type":"code","source":"train_target_data = {'text':X_train_targets, 'label':y_train_targets_bin.tolist() }\ntest_target_data = {'text':X_test_targets, 'label':y_test_targets_bin.tolist() }\n\ndf_train_target = pd.DataFrame(train_target_data)\ndf_test_target  = pd.DataFrame(test_target_data )\n\n\ndf_train_target['tokens'] = df_train_target['text'].apply(nltk_tokenizer)\ndf_train_target['sentence'] =  df_train_target.tokens.apply(lambda x: ' '.join(x))\n\ndf_test_target['tokens'] = df_test_target['text'].apply(nltk_tokenizer)\ndf_test_target['sentence'] =  df_test_target.tokens.apply(lambda x: ' '.join(x))\n\ndata_train, data_test = create_embedding_vectors(emb_model = pretraines_glove_model, df_train = df_train, df_test = df_test, emb_dim = pretraines_glove_model.vector_size)\n\ndata_train_targets, data_test_targets = create_embedding_vectors(emb_model = pretraines_glove_model, df_train = df_train_target, df_test = df_test_target, emb_dim = pretraines_glove_model.vector_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:18:23.296679Z","iopub.execute_input":"2024-06-18T19:18:23.297147Z","iopub.status.idle":"2024-06-18T19:18:33.512317Z","shell.execute_reply.started":"2024-06-18T19:18:23.297115Z","shell.execute_reply":"2024-06-18T19:18:33.511366Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"max lenght: 144\n words not found: 5171\nmax lenght: 144\n words not found: 5171\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now we will create a custom dataset to train the birnn pytorch model for text classification","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\n\nclass GloveDataset(Dataset):\n    def __init__(self, data):\n        self.dataset = data\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        embeddings, label = self.dataset[idx]\n        embeddings = torch.tensor(embeddings, dtype=torch.float32)\n        label = torch.tensor(label, dtype=torch.long)\n        embeddings = embeddings.to(device)\n        label = label.to(device)\n        return embeddings, label\n\nclass GloveDataset_target(Dataset):\n    def __init__(self, data):\n        self.dataset = data\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        embeddings, label = self.dataset[idx]\n        embeddings = torch.tensor(embeddings, dtype=torch.float32)\n        label = torch.tensor(label, dtype=torch.float32)\n        embeddings = embeddings.to(device)\n        label = label.to(device)\n        return embeddings, label\n\n\n\nbatch_size = 16\n\n# hate_speech classification dataloaders\ndataset = GloveDataset(data_train)\ndataloader_glove_train = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\ntest_dataset = GloveDataset(data_test)\ndataloader_glove_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n\n# target classification dataloaders\n\ndataset_target = GloveDataset_target(data_train_targets)\ndataloader_glove_target_train = DataLoader(dataset_target, batch_size=batch_size, shuffle=True)\n\ntest_dataset_target = GloveDataset_target(data_test_targets)\ndataloader_glove_target_test = DataLoader(test_dataset_target, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:18:33.513985Z","iopub.execute_input":"2024-06-18T19:18:33.514307Z","iopub.status.idle":"2024-06-18T19:18:33.526173Z","shell.execute_reply.started":"2024-06-18T19:18:33.514279Z","shell.execute_reply":"2024-06-18T19:18:33.525265Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### Generic readapted BiRNN model\nsource: https://github.com/hate-alert/HateXplain/blob/master/Models/otherModels.py","metadata":{}},{"cell_type":"code","source":"from torch import nn\n\nclass BiRNN(nn.Module):  \n    def __init__(self,args):\n        super(BiRNN, self).__init__()\n        \n        self.hidden_size = args['hidden_size']\n        self.batch_size = args['batch_size']\n        self.drop_embed=args['drop_embed']\n        self.drop_fc=args['drop_fc']\n        self.drop_hidden=args['drop_hidden']\n        self.seq_model_name=args[\"seq_model\"]\n        self.embedsize=args[\"embed_size\"]\n        self.num_layers = args[\"num_layers\"]\n  \n       \n\n        \n        if(args[\"seq_model\"]==\"lstm\"):\n            self.seq_model = nn.LSTM(args[\"embed_size\"], self.hidden_size,num_layers =self.num_layers, bidirectional=True, batch_first=True,dropout=self.drop_hidden)\n        elif(args[\"seq_model\"]==\"gru\"):\n            self.seq_model = nn.GRU(args[\"embed_size\"], self.hidden_size, num_layers=self.num_layers, bidirectional=True, batch_first=True,dropout=self.drop_hidden) \n            \n        self.linear1 = nn.Linear(2 * self.hidden_size*self.num_layers, self.hidden_size)\n        self.linear2 = nn.Linear(self.hidden_size, args['num_classes'])\n        self.dropout_embed = nn.Dropout2d(self.drop_embed)\n        self.dropout_fc = nn.Dropout(self.drop_fc)\n        self.num_labels=args['num_classes']\n        \n        \n        \n    def forward(self,X):\n        batch_size = X.size(0)\n        h_embedding = torch.squeeze(self.dropout_embed(torch.unsqueeze(X, 0))).view(batch_size, X.shape[1], self.embedsize)\n        \n        # Forward propagate through LSTM/GRU\n        if self.seq_model_name == \"lstm\":\n            _, hidden = self.seq_model(h_embedding)\n            hidden = hidden[0]\n        else:\n            _, hidden = self.seq_model(h_embedding)\n\n       \n     \n        hidden = hidden.transpose(0, 1).contiguous().view(X.size(0), -1) \n        hidden = self.dropout_fc(hidden)\n        hidden = torch.relu(self.linear1(hidden))  #batch x hidden_size\n        hidden = self.dropout_fc(hidden)\n        logits = self.linear2(hidden)\n        \n        return (logits)\n    \n    \n    \n    def init_hidden(self, batch_size):\n        return cuda_available(torch.zeros(2, self.batch_size, self.hidden_size))\n    \n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:20:25.036693Z","iopub.execute_input":"2024-06-18T19:20:25.037165Z","iopub.status.idle":"2024-06-18T19:20:25.050624Z","shell.execute_reply.started":"2024-06-18T19:20:25.037133Z","shell.execute_reply":"2024-06-18T19:20:25.049569Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# model for hatespeech classification\nargs_dict_classification_hate = {\n        \"batch_size\":16,\n        \"hidden_size\":320,\n        \"embed_size\":100,\n        \"num_classes\" : 3,\n        \"num_layers\":3,\n        \"drop\":0.1,\n        \"learning_rate\":0.001,\n        \"seq_model\":\"lstm\",\n        \"drop_embed\":0.1,\n        \"drop_fc\":0.1,\n        \"drop_hidden\":0.1,\n        }\n    \nBiRNN_for_hate_class = BiRNN(args_dict_classification_hate)\nBiRNN_for_hate_class.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:20:30.081118Z","iopub.execute_input":"2024-06-18T19:20:30.081489Z","iopub.status.idle":"2024-06-18T19:20:30.456633Z","shell.execute_reply.started":"2024-06-18T19:20:30.081459Z","shell.execute_reply":"2024-06-18T19:20:30.455753Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"BiRNN(\n  (seq_model): LSTM(100, 320, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n  (linear1): Linear(in_features=1920, out_features=320, bias=True)\n  (linear2): Linear(in_features=320, out_features=3, bias=True)\n  (dropout_embed): Dropout2d(p=0.1, inplace=False)\n  (dropout_fc): Dropout(p=0.1, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-18T17:50:38.881506Z","iopub.execute_input":"2024-06-18T17:50:38.881868Z","iopub.status.idle":"2024-06-18T17:50:38.888052Z","shell.execute_reply.started":"2024-06-18T17:50:38.881837Z","shell.execute_reply":"2024-06-18T17:50:38.887158Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"12"},"metadata":{}}]},{"cell_type":"code","source":"#model for target classification \n\nn_classes = len(y_train_targets_bin[0])\nargs_dict_classification_target = {\n        \"batch_size\":16,\n        \"hidden_size\":320,\n        \"embed_size\":100,\n        \"num_classes\" : n_classes ,\n        \"num_layers\":3,\n        \"drop\":0.1,\n        \"learning_rate\":0.001,\n        \"seq_model\":\"lstm\",\n        \"drop_embed\":0.1,\n        \"drop_fc\":0.1,\n        \"drop_hidden\":0.1,\n        }\n    \nBiRNN_for_target_class = BiRNN(args_dict_classification_target)\nBiRNN_for_target_class.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:29:45.829815Z","iopub.execute_input":"2024-06-18T19:29:45.830269Z","iopub.status.idle":"2024-06-18T19:29:45.908161Z","shell.execute_reply.started":"2024-06-18T19:29:45.830237Z","shell.execute_reply":"2024-06-18T19:29:45.907266Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"BiRNN(\n  (seq_model): LSTM(100, 320, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n  (linear1): Linear(in_features=1920, out_features=320, bias=True)\n  (linear2): Linear(in_features=320, out_features=12, bias=True)\n  (dropout_embed): Dropout2d(p=0.1, inplace=False)\n  (dropout_fc): Dropout(p=0.1, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"\nfrom torch import nn\nfrom sklearn import metrics\nimport torch.nn.functional as F\n\ndef calculate_metrics(preds, labels, task):\n    # preds are softmax if task is hate_speech otherwise sigmoid\n    if task == 'hate_speech':\n        preds_label = np.argmax(preds, axis=1)\n    elif task == 'target_clf':\n        preds = torch.sigmoid(torch.tensor(preds)).numpy()\n        preds_label = (preds > 0.5).astype(int)\n    \n    else:\n        raise ValueError(\"please provde a valid task between ['hate_speech', 'target_clf']\")\n    \n    \n    accuracy = metrics.accuracy_score(labels, preds_label)\n    macro_f1 = metrics.f1_score(labels, preds_label, average = \"macro\")\n    auroc = metrics.roc_auc_score(labels, preds, multi_class='ovr')\n    \n    return accuracy, macro_f1, auroc\n\n\ndef custom_trainer(model, dataloader, num_epochs, criterion, optimizer, task = None):\n    \n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        for embeddings, labels in dataloader:\n            # Move tensors to the configured device\n            \n            embeddings = embeddings.to(device)\n            labels = labels.to(device)\n            \n\n            # Forward pass\n            outputs = model(embeddings)\n            loss = criterion(outputs, labels)\n\n            # Backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n        avg_loss = running_loss / len(dataloader)\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n\n        # Validation step\n        model.eval()\n        all_preds = []\n        all_labels = []\n        with torch.no_grad():\n            for embeddings, labels in dataloader:\n                embeddings = embeddings.to(device)\n                labels = labels.to(device)\n                outputs = model(embeddings) \n                \n                if task == 'hate_speech':\n                    outputs = F.softmax(outputs, dim=1)\n                \n                    \n                all_preds.extend(outputs.cpu().numpy())\n                all_labels.extend(labels.cpu().numpy())\n\n        accuracy, macro_f1, auroc = calculate_metrics(all_preds, all_labels,task=task)\n        print(f'Accuracy: {accuracy:.4f}, Macro F1: {macro_f1:.4f},AUROC: {auroc:.4f}')\n    \n    return model\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:29:49.210766Z","iopub.execute_input":"2024-06-18T19:29:49.211609Z","iopub.status.idle":"2024-06-18T19:29:49.224442Z","shell.execute_reply.started":"2024-06-18T19:29:49.211572Z","shell.execute_reply":"2024-06-18T19:29:49.223400Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"### Train the hate speech classifier","metadata":{}},{"cell_type":"code","source":"from torch import optim\nfrom torch import nn\n\ncriterion = criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(BiRNN_for_hate_class.parameters(), lr=0.001)\n\nBiRNN_for_hate_class = custom_trainer(BiRNN_for_hate_class, dataloader_glove_train, 5,criterion,optimizer,task = 'hate_speech' )","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:47:09.141797Z","iopub.execute_input":"2024-06-18T19:47:09.142676Z","iopub.status.idle":"2024-06-18T19:52:18.303778Z","shell.execute_reply.started":"2024-06-18T19:47:09.142640Z","shell.execute_reply":"2024-06-18T19:52:18.302838Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Epoch [1/5], Loss: 0.8574\nVAccuracy: 0.6592, Macro F1: 0.6111,AUROC: 0.8187\nEpoch [2/5], Loss: 0.8138\nVAccuracy: 0.6905, Macro F1: 0.6388,AUROC: 0.8468\nEpoch [3/5], Loss: 0.8250\nVAccuracy: 0.4876, Macro F1: 0.3469,AUROC: 0.6043\nEpoch [4/5], Loss: 0.9862\nVAccuracy: 0.5497, Macro F1: 0.4136,AUROC: 0.7290\nEpoch [5/5], Loss: 0.8977\nVAccuracy: 0.6113, Macro F1: 0.4601,AUROC: 0.7750\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Train target classifier \n","metadata":{}},{"cell_type":"code","source":"from torch import optim\nfrom torch import nn\n\ncriterion = nn.BCEWithLogitsLoss() # combines a sigmoid layer and the binary cross-entropy loss in a single class for a good multi-class multi target classification loss\noptimizer = optim.Adam(BiRNN_for_target_class.parameters(), lr=0.001)\n\nBiRNN_for_target_class = custom_trainer(BiRNN_for_target_class, dataloader_glove_target_train, 10, criterion,optimizer, task = 'target_clf' )","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:29:54.040326Z","iopub.execute_input":"2024-06-18T19:29:54.040688Z","iopub.status.idle":"2024-06-18T19:34:31.745207Z","shell.execute_reply.started":"2024-06-18T19:29:54.040659Z","shell.execute_reply":"2024-06-18T19:34:31.743965Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Epoch [1/10], Loss: 0.2242\nVAccuracy: 0.4758, Macro F1: 0.4131,AUROC: 0.8801\nEpoch [2/10], Loss: 0.1724\nVAccuracy: 0.5634, Macro F1: 0.5537,AUROC: 0.9243\nEpoch [3/10], Loss: 0.1525\nVAccuracy: 0.6478, Macro F1: 0.6190,AUROC: 0.9489\nEpoch [4/10], Loss: 0.1401\nVAccuracy: 0.6764, Macro F1: 0.6324,AUROC: 0.9604\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[41], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss() \u001b[38;5;66;03m# combines a sigmoid layer and the binary cross-entropy loss in a single class for a good multi-class multi target classification loss\u001b[39;00m\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(BiRNN_for_target_class\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m BiRNN_for_target_class \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBiRNN_for_target_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_glove_target_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget_clf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[40], line 45\u001b[0m, in \u001b[0;36mcustom_trainer\u001b[0;34m(model, dataloader, num_epochs, criterion, optimizer, task)\u001b[0m\n\u001b[1;32m     42\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     43\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 45\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"## Test and final pipeline","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, dataloader,task):# mode eval\n    \n    model.to(device)\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for embeddings, labels in dataloader:\n            embeddings = embeddings.to(device)\n            labels = labels.to(device)\n            outputs = model(embeddings) \n                \n            if task == 'hate_speech':\n                outputs = F.softmax(outputs, dim=1)\n                \n                    \n            all_preds.extend(outputs.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy, macro_f1, auroc = calculate_metrics(all_preds, all_labels,task=task)\n    print(f'VAccuracy: {accuracy:.4f}, Macro F1: {macro_f1:.4f},AUROC: {auroc:.4f}')\n    \n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:42:00.717955Z","iopub.execute_input":"2024-06-18T19:42:00.718346Z","iopub.status.idle":"2024-06-18T19:42:00.725737Z","shell.execute_reply.started":"2024-06-18T19:42:00.718314Z","shell.execute_reply":"2024-06-18T19:42:00.724795Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"### Test Hate classification task","metadata":{}},{"cell_type":"code","source":"evaluate_model(BiRNN_for_hate_class, dataloader_glove_test, task =  'hate_speech')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T14:37:53.516813Z","iopub.execute_input":"2024-06-18T14:37:53.517501Z","iopub.status.idle":"2024-06-18T14:37:55.689703Z","shell.execute_reply.started":"2024-06-18T14:37:53.517472Z","shell.execute_reply":"2024-06-18T14:37:55.688789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test Target classification task","metadata":{}},{"cell_type":"code","source":"evaluate_model(BiRNN_for_target_class, dataloader_glove_target_test, task = 'target_clf')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:42:04.600510Z","iopub.execute_input":"2024-06-18T19:42:04.601119Z","iopub.status.idle":"2024-06-18T19:42:06.659216Z","shell.execute_reply.started":"2024-06-18T19:42:04.601086Z","shell.execute_reply":"2024-06-18T19:42:06.658250Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"VAccuracy: 0.5947, Macro F1: 0.5938,AUROC: 0.9277\n","output_type":"stream"}]},{"cell_type":"markdown","source":"save model","metadata":{}},{"cell_type":"code","source":"torch.save(BiRNN_for_hate_class, 'BiRNN_for_hate_class.pth')\ntorch.save(BiRNN_for_hate_class, 'BiRNN_for_target_class.pth')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T20:16:57.527746Z","iopub.execute_input":"2024-06-18T20:16:57.528880Z","iopub.status.idle":"2024-06-18T20:16:57.612470Z","shell.execute_reply.started":"2024-06-18T20:16:57.528829Z","shell.execute_reply":"2024-06-18T20:16:57.611691Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"## Final wrapper for custom input \n\nOutput hate score and targets","metadata":{}},{"cell_type":"code","source":"def predict(text,hate_model,target_model, emb_model,  max_len=144, emb_dim = 100):\n    # Tokenize the input text\n\n    tokens = nltk_tokenizer(text)\n    predict_embeddings = []\n    emb_list = []\n    \n    embeddings = [get_word_embedding(emb_model,token,emb_dim) for token in tokens] \n    \n        \n    padded_embeddings = pad_sequence(embeddings, max_len, emb_dim)\n        \n    predict_embeddings.append(padded_embeddings)\n\n\n    tensor_emb = torch.tensor(predict_embeddings, dtype= torch.float32)\n    tensor_emb = tensor_emb.to(device)\n    \n    predictions = []\n    # Perform prediction for hate\n    with torch.no_grad():\n        outputs = hate_model(tensor_emb)\n        proba = F.softmax(outputs,dim=1)\n        \n        predictions.append(proba.cpu())\n    \n    # perform prediction for targets\n    with torch.no_grad():\n        outputs = target_model(tensor_emb)\n        \n       \n        predictions.append(outputs.cpu())\n        \n    return predictions\n    \n    \n\n# Example custom input\ncustom_input = \"always thought that nigger was a faggot\"\n\n# Predict the class for the custom input\npredict = predict(text = custom_input, hate_model = BiRNN_for_hate_class, target_model = BiRNN_for_target_class,emb_model = pretraines_glove_model)\n\n\nhate_argmax = np.argmax(predict[0][0]).numpy().item()\n\nhate_dict = {0: 'normal', 1:'offensive', 2:'hate speech'}\n\nhate_label = hate_dict[hate_argmax]\nhate_label_score = predict[0][0][hate_argmax].numpy().item()\n\n\nmultilabel.classes_\n\nsigmoid = torch.nn.Sigmoid()\nprobs = sigmoid(predict[1][0].cpu())\npreds = np.zeros(probs.shape)\npreds[np.where(probs>=0.3)] = 1\n\ntarget_label = multilabel.inverse_transform(preds.reshape(1,-1))\n\n\nprint(f'Hate score: {hate_label}')\n\nprint(f'Probability: {hate_label_score}')\n      \nprint(f'Targets: {target_label}')\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T20:15:01.767150Z","iopub.execute_input":"2024-06-18T20:15:01.768041Z","iopub.status.idle":"2024-06-18T20:15:01.809778Z","shell.execute_reply.started":"2024-06-18T20:15:01.768004Z","shell.execute_reply":"2024-06-18T20:15:01.808940Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Hate score: hate speech\nProbability: 0.9415609240531921\nTargets: [('African', 'Homosexual')]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Train ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}